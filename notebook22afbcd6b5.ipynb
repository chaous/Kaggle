{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport pydicom\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nfrom skimage.transform import resize\nimport torch.nn.functional as F\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\ntorch.cuda.empty_cache()\nFLAIR_MAX_LEN = 514\nT1W_MAX_LEN = 400\nT1WCE_MAX_LEN = 400\nT2W_MAX_LEN = 472\nVIDEO_NUMBER = 585\nfrom matplotlib import pyplot as plt\nfrom torch.nn import functional as torch_functional\nimport time\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-21T08:54:25.908332Z","iopub.execute_input":"2021-09-21T08:54:25.908704Z","iopub.status.idle":"2021-09-21T08:54:25.999165Z","shell.execute_reply.started":"2021-09-21T08:54:25.908672Z","shell.execute_reply":"2021-09-21T08:54:25.998358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet_pytorch\n!conda install pytorch torchvision cudatoolkit=9.0 -c pytorch\n#!pip install torchsummary\nfrom efficientnet_pytorch import EfficientNet\n#print(os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/00001'))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T08:54:32.366045Z","iopub.execute_input":"2021-09-21T08:54:32.366391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_dir = '../input/rsna-miccair-bain-tumor-radiogenomic-classification/'\nprint(len(os.listdir(root_dir + 'train')))","metadata":{"execution":{"iopub.status.busy":"2021-09-07T13:58:57.400211Z","iopub.execute_input":"2021-09-07T13:58:57.400482Z","iopub.status.idle":"2021-09-07T13:58:57.40822Z","shell.execute_reply.started":"2021-09-07T13:58:57.400451Z","shell.execute_reply":"2021-09-07T13:58:57.40684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image(data, size_x = 256, size_y = 256):\n    '''\n    Returns the image data as a numpy array.\n    '''  \n    if np.max(data.pixel_array)==0:\n        img = data.pixel_array\n    else:\n        img = data.pixel_array/np.max(data.pixel_array)\n        img = (img * 255).astype(np.uint8)\n    return resize(img, (size_x, size_y))\n\ndata = pydicom.dcmread('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00000/T1w/Image-24.dcm')\nimg = get_image(data)\n#print(img[128])\nimg = resize(img, (256, 256))\nprint(np.max(img))\nplt.imshow(img, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2021-09-21T08:52:06.394745Z","iopub.execute_input":"2021-09-21T08:52:06.395019Z","iopub.status.idle":"2021-09-21T08:52:06.669604Z","shell.execute_reply.started":"2021-09-21T08:52:06.394988Z","shell.execute_reply":"2021-09-21T08:52:06.668801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = 0\nfor i in tqdm(os.listdir((root_dir + 'train/'))):\n        l = len(os.listdir(root_dir + 'train/' + i + '/' + 'T2w'))\n        if l > max_len:\n            max_len = l\nprint(max_len)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T13:58:57.641306Z","iopub.execute_input":"2021-09-07T13:58:57.641663Z","iopub.status.idle":"2021-09-07T13:59:02.120005Z","shell.execute_reply.started":"2021-09-07T13:58:57.641627Z","shell.execute_reply":"2021-09-07T13:59:02.117538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_dir = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/'\ndef load_data(root_dir, batch_size, number, answers_dir = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv',\n              size_x = 256, size_y = 256):\n    # returns 4 numpy arrays of padded video(4 dim) and array of answers\n    video_dir = os.listdir(root_dir)\n    video_dir.sort()\n    video_number = len(video_dir)\n    arrays_size = batch_size\n    if number * batch_size > video_number:\n        raise Exception('out of range')\n    if number * batch_size + batch_size > video_number:\n        arrays_size = video_number - number * batch_size\n    x = np.full((arrays_size, FLAIR_MAX_LEN, size_x, size_y), 0.0)\n    y = np.full((arrays_size, T1W_MAX_LEN, size_x, size_y), 0.0)\n    z = np.full((arrays_size, T1WCE_MAX_LEN, size_x, size_y), 0.0)\n    w = np.full((arrays_size, T2W_MAX_LEN, size_x, size_y), 0.0)\n    answers = np.full((arrays_size), 0.0)\n    df = pd.read_csv(answers_dir)\n    for i in range(number * batch_size, number * batch_size + arrays_size):\n        dir_flair = os.listdir(root_dir + video_dir[i] + '/FLAIR')\n        dir_flair.sort()\n        dir_t1w = os.listdir(root_dir + video_dir[i] + '/T1w')\n        dir_t1w.sort()\n        dir_t1wc = os.listdir(root_dir + video_dir[i] + '/T1wCE')\n        dir_t1wc.sort()\n        dir_t2w = os.listdir(root_dir + video_dir[i] + '/T2w')\n        dir_t2w.sort()\n        answers[i - number * batch_size] = int(df[df['BraTS21ID'] == int(video_dir[i])]['MGMT_value'])\n        #print(root_dir + video_dir[i])\n        for j in range(len(dir_flair)):\n            data = pydicom.dcmread(root_dir + video_dir[i] + '/FLAIR/' + dir_flair[j])\n            x[i - number * batch_size][j] = get_image(data, size_x, size_y)\n        for j in range(len(dir_t1w)):\n            data = pydicom.dcmread(root_dir + video_dir[i] + '/T1w/' + dir_t1w[j])\n            y[i - number * batch_size][j] = get_image(data, size_x, size_y)\n        for j in range(len(dir_t1wc)):\n            data = pydicom.dcmread(root_dir + video_dir[i] + '/T1wCE/' + dir_t1wc[j])\n            z[i - number * batch_size][j] = get_image(data, size_x, size_y)\n        for j in range(len(dir_t2w)):\n            data = pydicom.dcmread(root_dir + video_dir[i] + '/T2w/' + dir_t2w[j])\n            w[i - number * batch_size][j] = get_image(data, size_x, size_y)\n    return x, y, z, w, answers\n\ndef load_data_resized(root_dir, batch_size, number, answers_dir = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv',\n              size_x = 256, size_y = 256, resize_FLAIR_MAX_LEN = 514, resize_T1W_MAX_LEN = 400, resize_T1WCE_MAX_LEN = 400, resize_T2W_MAX_LEN = 472):\n    # returns 4 numpy arrays of padded video(4 dim) and array of answers\n    # resize output data\n    video_dir = os.listdir(root_dir)\n    video_dir.sort()\n    #print(video_dir)\n    video_number = len(video_dir)\n    arrays_size = batch_size\n    if number * batch_size > video_number:\n        raise Exception('out of range')\n    if number * batch_size + batch_size > video_number:\n        arrays_size = video_number - number * batch_size\n    x = np.full((arrays_size, resize_FLAIR_MAX_LEN, size_x, size_y), 0.0)\n    y = np.full((arrays_size, resize_T1W_MAX_LEN, size_x, size_y), 0.0)\n    z = np.full((arrays_size, resize_T1WCE_MAX_LEN, size_x, size_y), 0.0)\n    w = np.full((arrays_size, resize_T2W_MAX_LEN, size_x, size_y), 0.0)\n    answers = np.full((arrays_size), 0.0)\n    df = pd.read_csv(answers_dir)\n    for i in range(number * batch_size, number * batch_size + arrays_size):\n        #print((root_dir + video_dir[i] +'/FLAIR'))\n        dir_flair = os.listdir(root_dir + video_dir[i] +'/FLAIR')\n        dir_flair.sort()\n        dir_t1w = os.listdir(root_dir + video_dir[i] + '/T1w')\n        dir_t1w.sort()\n        dir_t1wc = os.listdir(root_dir + video_dir[i] + '/T1wCE')\n        dir_t1wc.sort()\n        dir_t2w = os.listdir(root_dir + video_dir[i] + '/T2w')\n        dir_t2w.sort()\n        answers[i - number * batch_size] = int(df[df['BraTS21ID'] == int(video_dir[i])]['MGMT_value'])\n        #print(int(df[df['BraTS21ID'] == int(video_dir[i])]['MGMT_value']))\n        #print(root_dir + video_dir[i])\n        for j in range(min(resize_FLAIR_MAX_LEN, len(dir_flair))):\n            data = pydicom.dcmread(root_dir + video_dir[i] + '/FLAIR/' + dir_flair[j])\n            x[i - number * batch_size][j] = get_image(data, size_x, size_y)\n        for j in range(min(resize_T1W_MAX_LEN, len(dir_t1w))):\n            data = pydicom.dcmread(root_dir + video_dir[i] + '/T1w/' + dir_t1w[j])\n            y[i - number * batch_size][j] = get_image(data, size_x, size_y)\n        for j in range(min(resize_T1WCE_MAX_LEN, len(dir_t1wc))):\n            data = pydicom.dcmread(root_dir + video_dir[i] + '/T1wCE/' + dir_t1wc[j])\n            z[i - number * batch_size][j] = get_image(data, size_x, size_y)\n        for j in range(min(resize_T2W_MAX_LEN, len(dir_t2w))):\n            data = pydicom.dcmread(root_dir + video_dir[i] + '/T2w/' + dir_t2w[j])\n            w[i - number * batch_size][j] = get_image(data, size_x, size_y)\n    return x, y, z, w, answers\n\n\ndef transform_array(numpy_array, new_len = 32):\n    l = []\n    for i in range(new_len, len(numpy_array[0])):\n        l.append(i)\n    return np.delete(numpy_array, l, 1)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T08:52:11.774179Z","iopub.execute_input":"2021-09-21T08:52:11.77454Z","iopub.status.idle":"2021-09-21T08:52:11.801124Z","shell.execute_reply.started":"2021-09-21T08:52:11.774506Z","shell.execute_reply":"2021-09-21T08:52:11.800171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y, z, w, answers = load_data_resized(root_dir, 1, 0, resize_FLAIR_MAX_LEN = 32,\n                                                resize_T1W_MAX_LEN = 32, resize_T1WCE_MAX_LEN = 32, resize_T2W_MAX_LEN = 32)\n\n#plt.imshow(x[0][0], cmap='gray')\nplt.imshow(x[0][2], cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2021-09-07T19:48:14.786349Z","iopub.execute_input":"2021-09-07T19:48:14.78669Z","iopub.status.idle":"2021-09-07T19:48:17.371464Z","shell.execute_reply.started":"2021-09-07T19:48:14.78666Z","shell.execute_reply":"2021-09-07T19:48:17.370629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification' + '/train_labels.csv')\ndf[df['BraTS21ID'] == 2]","metadata":{"execution":{"iopub.status.busy":"2021-09-07T13:59:14.930702Z","iopub.execute_input":"2021-09-07T13:59:14.931016Z","iopub.status.idle":"2021-09-07T13:59:14.947861Z","shell.execute_reply.started":"2021-09-07T13:59:14.930986Z","shell.execute_reply":"2021-09-07T13:59:14.946927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''class Video_preprocess(nn.Module):\n    def __init__(self):\n        super(Video_preprocess, self).__init__()\n        self.Flatten = nn.Flatten()\n        self.conv_process = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=16),\n            nn.Tanh(),\n            nn.MaxPool2d(4, 4),\n            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=32),\n            nn.Sigmoid(),\n            nn.MaxPool2d(4, 4)\n        )\n        self.gru1 = nn.GRU(input_size=49, hidden_size=256, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n        #self.fcx = nn.Linear(262144, 64200)\n    def forward(self, x):\n        #print(x.size())\n        x = self.conv_process(x)\n        x = torch.flatten(x, start_dim=2, end_dim=-1)\n        #print(x.size(0))\n        h0 = torch.zeros(3 * 2, x.size(0), 256).to(device)\n\n        x, h0 = self.gru1(x, h0)\n        #print(x)\n        return x, h0\n\n\n\n#test_video_preprocess = Video_preprocess()\n#test_tensor = torch.rand(1, 128, 256, 256)\n#test_video_preprocess(test_tensot)\n#test_video_preprocess(test_tensor)\n\n\n\n\n\n\n\nclass Video_classifier(nn.Module):\n    def __init__(self, FLAIR_MAX_LEN = 514, T1W_MAX_LEN = 400, T1WCE_MAX_LEN = 400, T2W_MAX_LEN = 472, size_x = 256, size_y = 256):\n        super(Video_classifier, self).__init__()\n        self.FLAIR_MAX_LEN = FLAIR_MAX_LEN\n        self.T1W_MAX_LEN = T1W_MAX_LEN\n        self.T1WCE_MAX_LEN = T1WCE_MAX_LEN\n        self.T2W_MAX_LEN = T2W_MAX_LEN\n        self.size_x = size_x\n        self.size_y = size_y\n\n\n        self.Flair_extraction = Video_preprocess()\n        self.T1w_extraction = Video_preprocess()\n        self.T1wce_extraction = Video_preprocess()\n        self.T2w_extraction = Video_preprocess()\n\n        self.GRU = nn.GRU(input_size=2048, hidden_size=1024, num_layers=3, bidirectional=True, dropout=0.1, batch_first=True)\n        self.Flatten = nn.Flatten()\n        self.fc1 = nn.Linear(1048576, 128)\n        #self.fc2 = nn.Linear(128000, 16000)\n        #self.fc3 = nn.Linear(2048, 64)\n        #self.fc4 = nn.Linear(256, 64)\n        self.fc5 = nn.Linear(128, 1)\n\n\n    def forward(self, x, y, z, w):\n        x, hx = self.Flair_extraction(x)\n        y, hy = self.T1w_extraction(y)\n        z, hz = self.T1wce_extraction(z)\n        w, hw = self.T2w_extraction(w)\n        #print(torch.numel(x) * 4)\n        #print(x.size())\n        h0 = torch.cat((hx, hy, hz, hw), 2).to(device)\n        x = torch.cat((x, y, z, w), 2).to(device)\n        #print(x.size())\n        #print(h0.size())\n        x, h0 = self.GRU(x, h0)\n        x = self.Flatten(x)\n        #print(x.size())\n        x = F.leaky_relu(self.fc1(x))\n        #x = F.leaky_relu(self.fc2(x))\n        #x = torch.sigmoid(self.fc3(x))\n        #x = F.tanh(self.fc4(x))\n        x = torch.sigmoid(self.fc5(x))\n        return x\n'''\n\n\nclass soft_max_linear(nn.Module):\n    def __init__(self):\n        super(soft_max_linear, self).__init__()\n        self.fc = nn.Linear(2560, 2)\n\n    def forward(self, x):\n        x = self.fc(x)\n        x = F.softmax(x, dim = 1)\n        return x\n\n\nclass TripleFrameProccess(nn.Module):\n    def __init__(self):\n        super(TripleFrameProccess, self).__init__()\n        self.model = EfficientNet.from_pretrained('efficientnet-b7')\n        self.model._fc = soft_max_linear()\n\n    def forward(self, x):\n        if torch.max(x) == 0:\n            l = []\n            for i in range(len(x)):\n                l.append([-1 , -1])\n            return torch.tensor(l).to(device)\n        x = self.model(x)\n        return x\n\nclass FolderPrediction(nn.Module):\n    def __init__(self):\n        super(FolderPrediction, self).__init__()\n        self.triple_frame_proccess = TripleFrameProccess()\n        self.BLSTM = nn.LSTM(input_size=4, hidden_size=64, num_layers=3, bidirectional=True, batch_first=True, dropout=0.1)\n\n    def forward(self, x):\n        x = x.unsqueeze(2).to(device)\n        # for now work only whit batch == 1\n        answers = torch.tensor([[]]).to(device);\n        for i in range(0,len(x[0]), 3):\n            y = torch.cat((torch.clone(x[0][i]), torch.clone(x[0][i + 1]),torch.clone(x[0][i + 2])), dim=0).to(device)\n            y = y.unsqueeze(0).to(device)\n            #print(y.size())\n            y = self.triple_frame_proccess(y)\n            answers = torch.cat((answers, y), dim=1).to(device)\n        #print(answers.size())\n        answers = torch.reshape(answers, (1, 2, 4)).to(device)\n        h0 = torch.zeros(3 * 2, answers.size(0), 64).to(device)\n        c0 = torch.zeros(3 * 2, answers.size(0), 64).to(device)\n        answers, (h0, c0) = self.BLSTM(answers, (h0, c0))\n        return answers, (h0, c0);\n\n\n\nclass TumorDetector(nn.Module):\n    def __init__(self):\n        super(TumorDetector, self).__init__()\n        self.Flair_extraction = FolderPrediction()\n        self.T1w_extraction = FolderPrediction()\n        self.T1wce_extraction = FolderPrediction()\n        self.T2w_extraction = FolderPrediction()\n        self.BLSTM = nn.LSTM(input_size=128, hidden_size=256, num_layers=3, bidirectional=True, dropout=0.1, batch_first=True)\n        self.fc1 = nn.Linear(4096, 256)\n        self.fc2 = nn.Linear(256, 1)\n\n\n    def forward(self, x, y, z, w):\n        x, (x0, cx0) = self.Flair_extraction(x)\n        y, (y0, cy0) = self.T1w_extraction(y)\n        z, (z0, cz0) = self.T1w_extraction(z)\n        w, (w0, cw0) = self.T2w_extraction(w)\n        #print(x.size())\n        x = torch.cat((x, y, z, w), dim=1).to(device)\n        h0 = torch.cat((x0, y0, z0, w0), dim=2).to(device)\n        c0 = torch.cat((cx0, cy0, cw0, cz0), dim=2).to(device)\n        #print(h0.size())\n        #print(x.size())\n        x, (h0, c0) = self.BLSTM(x, (h0, c0))\n        x = torch.flatten(x, start_dim=1).to(device)\n        #print(x.size())\n        x = F.relu(self.fc1(x))\n        x = torch.sigmoid(self.fc2(x))\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T08:52:20.80504Z","iopub.execute_input":"2021-09-21T08:52:20.805485Z","iopub.status.idle":"2021-09-21T08:52:20.827815Z","shell.execute_reply.started":"2021-09-21T08:52:20.80544Z","shell.execute_reply":"2021-09-21T08:52:20.826758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = TumorDetector()\n#model._fc = soft_max_linear(model._fc)\nmodel.to(device)\ncriterion = torch_functional.binary_cross_entropy_with_logits\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T08:52:24.244075Z","iopub.execute_input":"2021-09-21T08:52:24.244438Z","iopub.status.idle":"2021-09-21T08:52:28.858753Z","shell.execute_reply.started":"2021-09-21T08:52:24.244403Z","shell.execute_reply":"2021-09-21T08:52:28.857719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCKS = 1\nBATCH_SIZE = 1\nVAL_NUMBER = 32\n\n\ndef convert_value(x):\n    #print(x.shape)\n    if x < 0.5:\n        return 0.0\n    return 1.0\n\ndef print_acuracy(outputs, answers):\n    acuracy = 0\n    for i in range(len(answers)):\n        if (answers[i]) == convert_value((outputs[i])):\n            acuracy += 1\n    print(\"Acuracy == \", acuracy / VAL_NUMBER)\n    print(outputs)\n\ndef acuracy_chek(model):\n    acuracy = 0\n    for batch_number in tqdm(range(VAL_NUMBER // BATCH_SIZE)):\n        x, y, z, w, answers = load_data_resized(root_dir, BATCH_SIZE, batch_number,size_x = 224, size_y = 224\n                                                , resize_FLAIR_MAX_LEN = 12, resize_T1W_MAX_LEN = 12, resize_T1WCE_MAX_LEN = 12, resize_T2W_MAX_LEN = 12)\n        #x = np.expand_dims(x, axis=1)\n        #y = np.expand_dims(y, axis=1)\n        #z = np.expand_dims(z, axis=1)\n        #w = np.expand_dims(w, axis=1)\n        x = torch.from_numpy(x).to(device=device, dtype=torch.float)\n        y = torch.from_numpy(y).to(device=device, dtype=torch.float)\n        z = torch.from_numpy(z).to(device=device, dtype=torch.float)\n        w = torch.from_numpy(w).to(device=device, dtype=torch.float)\n        #x = torch.cat((x, y, z, w), 2).to(device)\n        answers = np.expand_dims(answers, axis=1)\n        answers = torch.from_numpy(answers).to(device=device, dtype=torch.float)\n        #answers = F.one_hot(answers.to(torch.int64), num_classes=2)\n        #answers = answers.to(torch.float)\n        outputs = model(x, y, z, w)\n        answers = answers.to(\"cpu\").detach().numpy()\n        outputs = outputs.to(\"cpu\").detach().numpy()\n        plt.plot(answers, label = \"answers\")\n        plt.plot(outputs, label = \"prediction\")\n        plt.show()\n        print(outputs)\n        for i in range(len(answers)):\n            if (answers[i]) == convert_value((outputs[i])):\n                acuracy += 1\n        \n    print(\"Acuracy == \", acuracy / VAL_NUMBER)\n    \n\n#model.eval()\n#acuracy_chek(model)\n    \n    \nfor epoch in range(NUM_EPOCKS):\n    running_loss = 0.0\n    model.train()\n    for batch_number in tqdm(range(VAL_NUMBER // BATCH_SIZE, VIDEO_NUMBER // BATCH_SIZE)):\n        \n        \n        x, y, z, w, answers = load_data_resized(root_dir, BATCH_SIZE, batch_number,size_x = 224, size_y = 224\n                                                , resize_FLAIR_MAX_LEN = 12, resize_T1W_MAX_LEN = 12, resize_T1WCE_MAX_LEN = 12, resize_T2W_MAX_LEN = 12)\n        answers = np.expand_dims(answers, axis=1)\n        #x = np.expand_dims(x, axis=1)\n        #y = np.expand_dims(y, axis=1)\n        #z = np.expand_dims(z, axis=1)\n        #w = np.expand_dims(w, axis=1)\n        #print(np.max(x))\n        x = torch.from_numpy(x).to(device=device, dtype=torch.float)\n        y = torch.from_numpy(y).to(device=device, dtype=torch.float)\n        z = torch.from_numpy(z).to(device=device, dtype=torch.float)\n        w = torch.from_numpy(w).to(device=device, dtype=torch.float)\n        answers = torch.from_numpy(answers).to(device=device, dtype=torch.float)\n        \n        #answers = F.one_hot(answers.to(torch.int64), num_classes=2)\n        #answers = answers.to(torch.float)\n        #x = torch.cat((x, y, z, w), 2).to(device)\n        outputs = model(x, y, z, w)\n        #print(outputs.size())\n        #print(torch.max(x))\n        loss = criterion(outputs, answers)\n        optimizer.zero_grad()\n        \n        loss.backward()\n        \n        optimizer.step()\n        running_loss += loss.item()\n        if batch_number % 5 == 0:\n            print(\"loss == \", running_loss / 5)\n            running_loss = 0.0\n        # print statistics\n    model.eval()\n    acuracy_chek(model)\ntorch.save(model, \"eff_net_model.ph\")","metadata":{"execution":{"iopub.status.busy":"2021-09-21T08:52:28.860556Z","iopub.execute_input":"2021-09-21T08:52:28.861Z","iopub.status.idle":"2021-09-21T08:52:30.423508Z","shell.execute_reply.started":"2021-09-21T08:52:28.860957Z","shell.execute_reply":"2021-09-21T08:52:30.42136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data_for_prediction(root_dir, batch_size, number, size_x = 256, size_y = 256,\n                             resize_FLAIR_MAX_LEN = 514, resize_T1W_MAX_LEN = 400, resize_T1WCE_MAX_LEN = 400, resize_T2W_MAX_LEN = 472):\n    video_dir = os.listdir(root_dir)\n    video_dir.sort()\n    # print(video_dir)\n    video_number = len(video_dir)\n    arrays_size = batch_size\n    if number * batch_size > video_number:\n        raise Exception('out of range')\n    if number * batch_size + batch_size > video_number:\n        arrays_size = video_number - number * batch_size\n    x = np.full((arrays_size, resize_FLAIR_MAX_LEN, size_x, size_y), 0.0)\n    y = np.full((arrays_size, resize_T1W_MAX_LEN, size_x, size_y), 0.0)\n    z = np.full((arrays_size, resize_T1WCE_MAX_LEN, size_x, size_y), 0.0)\n    w = np.full((arrays_size, resize_T2W_MAX_LEN, size_x, size_y), 0.0)\n    #answers = np.full((arrays_size), 0.0)\n    for i in range(number * batch_size, number * batch_size + arrays_size):\n        # print((root_dir + video_dir[i] +'/FLAIR'))\n        dir_flair = os.listdir(root_dir + video_dir[i] + '/FLAIR')\n        dir_flair.sort()\n        dir_t1w = os.listdir(root_dir + video_dir[i] + '/T1w')\n        dir_t1w.sort()\n        dir_t1wc = os.listdir(root_dir + video_dir[i] + '/T1wCE')\n        dir_t1wc.sort()\n        dir_t2w = os.listdir(root_dir + video_dir[i] + '/T2w')\n        dir_t2w.sort()\n        # print(int(df[df['BraTS21ID'] == int(video_dir[i])]['MGMT_value']))\n        # print(root_dir + video_dir[i])\n        for j in range(min(resize_FLAIR_MAX_LEN, len(dir_flair))):\n            data = pydicom.dcmread(root_dir + video_dir[i] + '/FLAIR/' + dir_flair[j])\n            x[i - number * batch_size][j] = get_image(data, size_x, size_y)\n        for j in range(min(resize_T1W_MAX_LEN, len(dir_t1w))):\n            data = pydicom.dcmread(root_dir + video_dir[i] + '/T1w/' + dir_t1w[j])\n            y[i - number * batch_size][j] = get_image(data, size_x, size_y)\n        for j in range(min(resize_T1WCE_MAX_LEN, len(dir_t1wc))):\n            data = pydicom.dcmread(root_dir + video_dir[i] + '/T1wCE/' + dir_t1wc[j])\n            z[i - number * batch_size][j] = get_image(data, size_x, size_y)\n        for j in range(min(resize_T2W_MAX_LEN, len(dir_t2w))):\n            data = pydicom.dcmread(root_dir + video_dir[i] + '/T2w/' + dir_t2w[j])\n            w[i - number * batch_size][j] = get_image(data, size_x, size_y)\n    return x, y, z, w, video_dir\n\n\n\ndef make_prediction(model, batch_size, tests_dir = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/'):\n    tests = os.listdir(tests_dir)\n    tests.sort()\n    predictions = {'BraTS21ID' : [],\n                   'MGMT_value' : []\n                   }\n    for i in tqdm(range(len(tests) // batch_size)):\n        x, y, z, w, video_dir = load_data_for_prediction(tests_dir, batch_size, i)\n        x = torch.from_numpy(x).to(device=device, dtype=torch.float)\n        y = torch.from_numpy(y).to(device=device, dtype=torch.float)\n        z = torch.from_numpy(z).to(device=device, dtype=torch.float)\n        w = torch.from_numpy(w).to(device=device, dtype=torch.float)\n        x = torch.cat((x, y, z, w), 2).to(device)\n        outputs = model(x)\n        outputs = outputs.tolist()\n        outputs = list(map(lambda x : x[1], outputs))\n        predictions['BraTS21ID'] += video_dir\n        predictions['MGMT_value'] += outputs\n    df = pd.DataFrame(predictions)\n    print(df.head)\n    df.to_csv(\"sumbmission.csv\", index=False)\n\n    \nmake_prediction(model, 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T16:45:44.763532Z","iopub.execute_input":"2021-09-13T16:45:44.763899Z","iopub.status.idle":"2021-09-13T16:45:56.80878Z","shell.execute_reply.started":"2021-09-13T16:45:44.763851Z","shell.execute_reply":"2021-09-13T16:45:56.806898Z"},"trusted":true},"execution_count":null,"outputs":[]}]}